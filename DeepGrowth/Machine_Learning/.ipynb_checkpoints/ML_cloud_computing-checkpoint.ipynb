{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for doing ML on cloud\n",
    "\n",
    "1. Logistic regression\n",
    "2. Random Forest/Decision Tree\n",
    "     2.1. Decision Tree\n",
    "     2.2. Random Forest\n",
    "     2.3. Imbalanced Random Forest\n",
    "     2.4. Best + Hyper parameterization\n",
    "3. Feed Forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: hyperas in /Users/dspaande/.local/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from hyperas) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: hyperopt in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperas) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: nbformat in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from hyperas) (5.0.4)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from hyperas) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperas) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from hyperopt->hyperas) (4.43.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperopt->hyperas) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.2 in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperopt->hyperas) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: future in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperopt->hyperas) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from hyperopt->hyperas) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from hyperopt->hyperas) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /Users/dspaande/.local/lib/python3.8/site-packages (from hyperopt->hyperas) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbformat->hyperas) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbformat->hyperas) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbformat->hyperas) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbformat->hyperas) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2>=2.4 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (2.11.1)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from nbconvert->hyperas) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jupyter->hyperas) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jupyter->hyperas) (5.1.4)\n",
      "Requirement already satisfied, skipping upgrade: qtconsole in /Users/dspaande/.local/lib/python3.8/site-packages (from jupyter->hyperas) (4.7.4)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jupyter->hyperas) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-console in /Users/dspaande/.local/lib/python3.8/site-packages (from jupyter->hyperas) (6.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from keras->hyperas) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /Users/dspaande/.local/lib/python3.8/site-packages (from keras->hyperas) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from networkx>=2.2->hyperopt->hyperas) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (46.0.0.post20200309)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.3.4 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from notebook->jupyter->hyperas) (6.0.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from notebook->jupyter->hyperas) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from notebook->jupyter->hyperas) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from notebook->jupyter->hyperas) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from notebook->jupyter->hyperas) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: appnope; platform_system == \"Darwin\" in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipykernel->jupyter->hyperas) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipykernel->jupyter->hyperas) (7.13.0)\n",
      "Requirement already satisfied, skipping upgrade: qtpy in /Users/dspaande/.local/lib/python3.8/site-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jupyter-console->jupyter->hyperas) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jupyter-client>=5.3.4->notebook->jupyter->hyperas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.2 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.6.2)\n",
      "Requirement already up-to-date: imbalanced-learn in /Users/dspaande/.local/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /Users/dspaande/.local/lib/python3.8/site-packages (from imbalanced-learn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from imbalanced-learn) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/dspaande/.local/lib/python3.8/site-packages (from imbalanced-learn) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/dspaande/.local/lib/python3.8/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
      "Requirement already up-to-date: scikit-learn in /Users/dspaande/.local/lib/python3.8/site-packages (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/miniconda3/envs/Broad_env/lib/python3.8/site-packages (from scikit-learn) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/dspaande/.local/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/dspaande/.local/lib/python3.8/site-packages (from scikit-learn) (1.19.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../Data/Ongoing/result.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_data', 'output_data', 'input_data_supplements', 'output_data_supplements', 'input_data_neural', 'output_data_neural'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data['input_data_supplements'])\n",
    "y = np.array(data['output_data_supplements'])\n",
    "X_neural = np.array(data['input_data_neural'])\n",
    "y_neural = np.array(data['output_data_neural'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[527  22]\n",
      " [ 45  71]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       549\n",
      "           1       0.76      0.61      0.68       116\n",
      "\n",
      "    accuracy                           0.90       665\n",
      "   macro avg       0.84      0.79      0.81       665\n",
      "weighted avg       0.89      0.90      0.89       665\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score: 89.92%\n",
      "Balanced accuracy score : 78.60%\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train , y_test = train_test_split(X, y, \n",
    "                                                     test_size=0.2, random_state=0)\n",
    "\n",
    "#Create model\n",
    "logisticRegr = LogisticRegression(max_iter=1000000, random_state=0)\n",
    "\n",
    "#Fit model\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "#Predictions\n",
    "predictions = logisticRegr.predict(x_test)\n",
    "\n",
    "#Print\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest/Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[506  43]\n",
      " [ 43  73]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       549\n",
      "           1       0.63      0.63      0.63       116\n",
      "\n",
      "    accuracy                           0.87       665\n",
      "   macro avg       0.78      0.78      0.78       665\n",
      "weighted avg       0.87      0.87      0.87       665\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score: 87.07%\n",
      "Balanced accuracy score : 77.55%\n"
     ]
    }
   ],
   "source": [
    "# With normal train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "x_train, x_test, y_train , y_test = train_test_split(X, y, \n",
    "                                                     test_size=0.2, random_state=0)\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "dtree.fit(x_train, y_train)\n",
    "predictions = dtree.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2593  177]\n",
      " [ 215  338]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2770\n",
      "           1       0.66      0.61      0.63       553\n",
      "\n",
      "    accuracy                           0.88      3323\n",
      "   macro avg       0.79      0.77      0.78      3323\n",
      "weighted avg       0.88      0.88      0.88      3323\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score: 88.20%\n",
      "Balanced accuracy score : 77.37%\n"
     ]
    }
   ],
   "source": [
    "# With stratified Kfold split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=0)\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "predictions = cross_val_predict(dtree, X, y, cv=skf, n_jobs=4)\n",
    "\n",
    "print(confusion_matrix(y, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[524  25]\n",
      " [ 54  62]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       549\n",
      "           1       0.71      0.53      0.61       116\n",
      "\n",
      "    accuracy                           0.88       665\n",
      "   macro avg       0.81      0.74      0.77       665\n",
      "weighted avg       0.87      0.88      0.87       665\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score: 88.12%\n",
      "Balanced accuracy score : 74.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "predictions_proba = rf.predict_proba(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2634  136]\n",
      " [ 253  300]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      2770\n",
      "           1       0.69      0.54      0.61       553\n",
      "\n",
      "    accuracy                           0.88      3323\n",
      "   macro avg       0.80      0.75      0.77      3323\n",
      "weighted avg       0.88      0.88      0.88      3323\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score: 88.29%\n",
      "Balanced accuracy score : 74.67%\n"
     ]
    }
   ],
   "source": [
    "# With stratified Kfold split\n",
    "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "\n",
    "predictions = cross_val_predict(rf, X, y, cv=skf, n_jobs=4)\n",
    "\n",
    "print(confusion_matrix(y, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a5464f10d0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=0, n_jobs=4)\n",
    "\n",
    "brf.fit(X_train, y_train)\n",
    "predictions = brf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np; np.random.seed(1)\n",
    "plt.rcParams[\"figure.figsize\"] = 10,4\n",
    "\n",
    "x_p = np.linspace(-3,3, num=len(brf.feature_importances_))\n",
    "y_p = brf.feature_importances_\n",
    "\n",
    "fig, (ax,ax2) = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "extent = [x_p[0]-(x_p[1]-x_p[0])/2., x_p[-1]+(x_p[1]-x_p[0])/2.,0,1]\n",
    "ax.imshow(y_p[np.newaxis,:], cmap=\"plasma\", aspect=\"auto\", extent=extent)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(extent[0], extent[1])\n",
    "\n",
    "ax2.plot(x_p,y_p)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best + Hyper parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth' : [None],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'oob_score': [True, False],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-66ef90617244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.ravel(predictions)\n",
    "predictions = [0 if x < 0.5 else 1 for x in predictions]\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somewhat deeper neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(312, input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(156, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.ravel(predictions)\n",
    "predictions = [0 if x < 0.5 else 1 for x in predictions]\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, predictions)*100:.2f}%')\n",
    "print(f\"Balanced accuracy score : {balanced_accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50cfef6f8305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(1110,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    # If we choose 'four', add an additional fourth layer\n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(Dense(100))\n",
    "\n",
    "        # We can also choose between complete sets of layers\n",
    "\n",
    "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size={{choice([64, 128])}},\n",
    "              epochs=2,\n",
    "              verbose=2,\n",
    "              validation_split=0.1)\n",
    "    \n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.ravel(predictions)\n",
    "    predictions = [0 if x < 0.5 else 1 for x in predictions]\n",
    "    recall = classification_report(y_test, predictions, output_dict=True)[\"1\"][\"recall\"]\n",
    "    \n",
    "    return {'loss': -recall, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import json\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, accuracy_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import metrics\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.tree import DecisionTreeClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, accuracy_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from collections import Counter\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import cross_val_predict, cross_val_score, StratifiedKFold\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imblearn.ensemble import BalancedRandomForestClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n",
      "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "module, class, method, function, traceback, frame, or code object was expected, got dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-186165e68954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                           notebook_name='ML_cloud_computing')\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./temp_model.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[0;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mfunctions_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_function_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mdata_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_data_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mretrieve_data_string\u001b[0;34m(data, verbose)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mretrieve_data_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mdata_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mfirst_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mindent_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetermine_indent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     OSError is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m--> 973\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    953\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    954\u001b[0m     \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mistraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    766\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0midentified\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \"\"\"\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZED_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    664\u001b[0m     raise TypeError('module, class, method, function, traceback, frame, or '\n\u001b[1;32m    665\u001b[0m                     'code object was expected, got {}'.format(\n\u001b[0;32m--> 666\u001b[0;31m                     type(object).__name__))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: module, class, method, function, traceback, frame, or code object was expected, got dict"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='ML_cloud_computing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 random.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
