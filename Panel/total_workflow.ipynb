{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maf_data(data, Path):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    if Path != False:\n",
    "        if not Path.endswith(\".pkl\"):\n",
    "            Path = Path + \"maf_extract.pkl\"\n",
    "        \n",
    "        data = pd.read_pickle(Path)\n",
    "\n",
    "    return data \n",
    "\n",
    "maf_data = maf_data(data=False, Path=\"../Data/Ongoing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently use sys to get other script\n",
    "import sys\n",
    "sys.path.insert(1, \"../Classes/\")\n",
    "from media_class import Medium, Supplement, GrowthMedium, Medium_one_hot, Supplement_one_hot, GrowthMedium_one_hot\n",
    "\n",
    "def other_data(data, Path):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    if Path != False:\n",
    "        if not Path.endswith(\".pkl\"):\n",
    "            Path = Path + \"after_media.pkl\"\n",
    "        \n",
    "        data = pd.read_pickle(Path)\n",
    "\n",
    "    return data \n",
    "\n",
    "meta_data = other_data(data=False, Path=\"../Data/Ongoing/after_media.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "@dataclass\n",
    "class one_hot:\n",
    "    counts: np.array\n",
    "    levels: np.array\n",
    "        \n",
    "    def sanity(self):\n",
    "        if len(self.counts.shape) == 1:\n",
    "            assert self.counts.shape[0] == len(self.levels)\n",
    "        else:\n",
    "            assert self.counts.shape[0] == len(self.levels[0])\n",
    "            assert self.counts.shape[1] == len(self.levels[1])\n",
    "        \n",
    "    def flatten(self):\n",
    "        counts = np.array([item for sublist in self.counts for item in sublist])\n",
    "        levels = np.array([str(x) + \":::\" + str(y) for x in self.levels[0] for y in self.levels[1]])\n",
    "        return one_hot(counts, levels)\n",
    "        \n",
    "    def make_2D(self, size):\n",
    "        counts = self.counts.reshape(int(len(self.counts)/size), size)\n",
    "        xlist,ylist = zip(*[x.split(\":::\") for x in self.levels])\n",
    "        levels = np.array([list(OrderedDict.fromkeys(xlist)), list(OrderedDict.fromkeys(ylist))])\n",
    "        return one_hot(counts, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create one-hot encoding for genes\n",
    "def one_hot_encoder(data, all_genes:list, all_alterations:list):\n",
    "    '''\n",
    "    \n",
    "    '''    \n",
    "    # Initialize empty arrays\n",
    "    gene_array = np.zeros(shape=(len(all_genes)))\n",
    "    gene_alteration_1D_array = np.zeros(shape=(len(all_alterations)))\n",
    "    \n",
    "    # Get all keys\n",
    "    gene = set(data[\"Hugo_Symbol\"])\n",
    "    gene_alt_1D = set(data[\"Hugo_Symbol\"] + \":::\" + data[\"Variant_Classification\"])\n",
    "    \n",
    "    #Get index\n",
    "    index_gene = [i for i, item in enumerate(all_genes) if item in gene]\n",
    "    index_gene_alt_1D = [i for i, item in enumerate(all_alterations) if item in gene_alt_1D]\n",
    "        \n",
    "    #Change 0 -> 1 for index\n",
    "    np.put(gene_array, index_gene, 1)\n",
    "    np.put(gene_alteration_1D_array, index_gene_alt_1D, 1)\n",
    "    \n",
    "    #Create class\n",
    "    flat = one_hot(gene_array, all_genes)\n",
    "    all_alt = one_hot(gene_alteration_1D_array, all_alterations)\n",
    "    \n",
    "    #2D array\n",
    "    all_alt_2D = all_alt.make_2D(int(len(all_alterations)/len(all_genes)))\n",
    "    \n",
    "    # Sanity checks\n",
    "    flat.sanity()\n",
    "    all_alt.sanity()\n",
    "    all_alt_2D.sanity()\n",
    "\n",
    "    #Create classes\n",
    "    return flat, all_alt, all_alt_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = maf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1 out of 177\n",
      "done 11 out of 177\n",
      "done 21 out of 177\n",
      "done 31 out of 177\n",
      "done 41 out of 177\n",
      "done 51 out of 177\n",
      "done 61 out of 177\n",
      "done 71 out of 177\n",
      "done 81 out of 177\n",
      "done 91 out of 177\n",
      "done 101 out of 177\n",
      "done 111 out of 177\n",
      "done 121 out of 177\n",
      "done 131 out of 177\n",
      "done 141 out of 177\n",
      "done 151 out of 177\n",
      "done 161 out of 177\n",
      "done 171 out of 177\n"
     ]
    }
   ],
   "source": [
    "data_summary = []\n",
    "unique_names = data[\"file\"].unique()\n",
    "all_genes = data[\"Hugo_Symbol\"].unique()\n",
    "#Remove Unknown\n",
    "all_genes = all_genes[all_genes != \"Unknown\"]\n",
    "all_alterations = data[\"Variant_Classification\"].unique()\n",
    "all_alterations = [str(x) + \":::\" + str(y) for x in all_genes for y in all_alterations]\n",
    "for i, name in enumerate(unique_names):\n",
    "    tmp_data = data[data[\"file\"] == name]\n",
    "    flat, all_alt, all_alt_2D = one_hot_encoder(tmp_data, all_genes, all_alterations)\n",
    "    \n",
    "    # Create dataframe\n",
    "    tmp_data = pd.DataFrame({\n",
    "                    \"File\": name,\n",
    "                    \"Flat_one_hot\": flat,\n",
    "                    \"Alt_one_hot\": all_alt,\n",
    "                    \"Alt_2D\": all_alt_2D\n",
    "    }, index=[0])\n",
    "    \n",
    "    \n",
    "    data_summary.append(tmp_data)\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(f'done {i+1} out of {len(unique_names)}')\n",
    "\n",
    "data_summary = pd.concat(data_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('Broad_env': virtualenv)",
   "language": "python",
   "name": "python38164bitbroadenvvirtualenvcc06190595da421ea68a050a83be054b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
